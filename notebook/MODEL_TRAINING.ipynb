{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score,recall_score,accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV,StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[449,['RestingBP','Cholesterol']] = np.nan\n",
    "df[df['Cholesterol']==0]['Cholesterol'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cholesterol'] = df['Cholesterol'].fillna(df['Cholesterol'].median())\n",
    "df['RestingBP'] = df['RestingBP'].fillna(df['RestingBP'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ExerciseAngina'] = df['ExerciseAngina'].map({'N':0,'Y':1})\n",
    "df['Sex'] = df['Sex'].map({'M':1,'F':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import TargetEncoder\n",
    "te = TargetEncoder()\n",
    "df['ST_Slope'] = te.fit_transform(df[['ST_Slope']],df['HeartDisease'])\n",
    "df['ChestPainType'] = te.fit_transform(df[['ChestPainType']],df['HeartDisease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = df[\"RestingECG\"].value_counts(normalize=True)\n",
    "df[\"RestingECG\"] = df[\"RestingECG\"].map(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(df[['HeartDisease']],axis=1)\n",
    "y = df['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "norm = Normalizer().set_output(transform='pandas')\n",
    "norm.fit(X)\n",
    "X = norm.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_with_gridsearch(models_with_params, X_train, X_test, y_train, y_test, metric=recall_score):\n",
    "    \"\"\"\n",
    "    Porównuje modele z RandomizedSearchCV na tych samych danych i zwraca najlepszy model z wynikami.\n",
    "    \n",
    "    Args:\n",
    "    - models_with_params (list): Lista krotek (nazwa_modelu, instancja_modelu, parametry).\n",
    "    - X_train, X_test (array): Dane treningowe i testowe (cechy).\n",
    "    - y_train, y_test (array): Dane treningowe i testowe (etykiety).\n",
    "    - metric (function): Funkcja oceny modelu (domyślnie accuracy_score).\n",
    "    \n",
    "    Returns:\n",
    "    - best_model_name (str): Nazwa najlepszego modelu.\n",
    "    - best_model (object): Instancja najlepszego modelu z optymalnymi hiperparametrami.\n",
    "    - results (dict): Wyniki najlepszych modeli po RandomizedSearchCV.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    best_model_name = None\n",
    "    best_model = None\n",
    "    best_score = float('-inf')\n",
    "    cv = StratifiedKFold(3)\n",
    "    \n",
    "    for name, model, params in models_with_params:\n",
    "        print(f\"Trenuję model: {name}\")\n",
    "        # GridSearchCV\n",
    "        grid = RandomizedSearchCV(estimator=model, param_distributions=params, scoring='f1', cv=cv, n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        # Przewidywanie na zbiorze testowym\n",
    "        y_pred = grid.best_estimator_.predict(X_test)\n",
    "        score = metric(y_test, y_pred)\n",
    "        results[name] = {\"Best Params\": grid.best_params_, \"\\nScore\": score}\n",
    "        print('--------------------------------------------')\n",
    "        print(classification_report(y_pred,y_test))\n",
    "        print('--------------------------------------------')\n",
    "        \n",
    "        # Zaktualizuj najlepszego modela\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model_name = name\n",
    "            best_model = grid.best_estimator_\n",
    "    \n",
    "    return best_model_name, best_model, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Decision tree params\n",
    "criterion = ['gini', 'entropy', 'log_loss']\n",
    "max_depth = [3,5,9,15,20]\n",
    "max_features = ['sqrt','log2']\n",
    "\n",
    "#Random Forest params\n",
    "n_estimators = [50,100,200]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "penalty = ['l1', 'l2', 'elasticnet',None]\n",
    "C = [0.01,0.1,1,0.0001,10]\n",
    "class_weight = ['balanced',None]\n",
    "solver = [ 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "gamma = ['scale','auto']\n",
    "\n",
    "\n",
    "#catboost_params\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "\n",
    "#xgb_params\n",
    "sampling_method = ['uniform','gradient_based']\n",
    "lma = [1,2,0.1,1.1]\n",
    "\n",
    "\n",
    "#gbclassifier\n",
    "loss = ['log_loss', 'exponential']\n",
    "\n",
    "\n",
    "params_svc = dict(C=C,kernel=kernel,class_weight=class_weight,gamma=gamma)\n",
    "params_lr = dict(penalty=penalty,C=C,class_weight=class_weight,solver=solver)\n",
    "params_dt = dict(criterion=criterion,max_depth=max_depth,max_features=max_features)\n",
    "params_rf = dict(criterion=criterion,max_depth=max_depth,max_features=max_features,n_estimators=n_estimators)\n",
    "params_ctb = dict(max_depth=max_depth,n_estimators=n_estimators,learning_rate=learning_rate)\n",
    "params_xgb = dict(max_depth=max_depth,reg_lambda = lma,sampling_method=sampling_method)\n",
    "params_ada = dict(n_estimators=n_estimators,learning_rate=learning_rate)\n",
    "params_gbst = dict(loss=loss,learning_rate=learning_rate,n_estimators=n_estimators,max_depth=max_depth)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models = [['LogisticRegression',LogisticRegression(),params_lr],\n",
    "          ['SVMclassifier',SVC(),params_svc],\n",
    "          ['DecisionTreeClassifier',DecisionTreeClassifier(),params_dt],\n",
    "          ['RandomForestClaasifier',RandomForestClassifier(),params_rf],\n",
    "          ['CatBoostClassifier',CatBoostClassifier(),params_ctb],\n",
    "          ['XGBoostClassifier',XGBClassifier(),params_xgb],\n",
    "          ['AdaBoostClassifier',AdaBoostClassifier(),params_ada],\n",
    "          ['GradientBoostingClassifier',GradientBoostingClassifier(),params_gbst]\n",
    "          ]\n",
    "\n",
    "name,model, results = compare_models_with_gridsearch(models,X_train,X_test,y_train,y_test)\n",
    "\n",
    "print(name)\n",
    "print(model)\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_test)\n",
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "dummy_model_prob = [0 for _ in range(len(y_test))]\n",
    "model_prob = model.predict_proba(X_test)\n",
    "model_prob = model_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model_auc = roc_auc_score(y_test,dummy_model_prob)\n",
    "model_auc = roc_auc_score(y_test,model_prob)\n",
    "print(dummy_model_auc)\n",
    "print(model_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_fpr,dummy_tpr,_ = roc_curve(y_test,dummy_model_prob)\n",
    "model_fpr,model_tpr,thresholds = roc_curve(y_test,model_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dummy_fpr,dummy_tpr,linestyle = '--',label='dummy_model')\n",
    "plt.plot(model_fpr,model_tpr,marker='.',label='Original model')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,50))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(dummy_fpr,dummy_tpr,linestyle = '--',label='dummy_model')\n",
    "plt.plot(model_fpr,model_tpr,marker='.',label='Logistic model')\n",
    "\n",
    "for i, xyz in enumerate(zip(model_fpr, model_tpr, thresholds)):\n",
    "    if i % 5 == 0:  # Co 5 punkt\n",
    "        ax.annotate('%s' % np.round(xyz[2], 2), xy=(xyz[0], xyz[1]))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend()\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = model.predict_proba(X_test)[:, 1]  # Prawdopodobieństwo klasy 1\n",
    "\n",
    "# Zmieniamy próg, np. na 0.7\n",
    "threshold = 0.36\n",
    "predictions = (probas >= threshold).astype(int)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
